# Parameter-Optimization-in-SVM

Support Vector Machines (SVMs) are supervised learning models in machine learning that employ associated learning algorithms to analyze data for classification and regression tasks. They seek to identify a hyperplane that effectively separates two classes or maximizes the margin between classes. SVMs are particularly suited for smaller datasets.

Result Table:

![image](https://github.com/svea-chawla/Parameter-Optimization-in-SVM/assets/111569685/e0322365-64f1-4950-a15b-008ce9395945)

Convergence Graph:

![image](https://github.com/svea-chawla/Parameter-Optimization-in-SVM/assets/111569685/df60232a-eb6a-43b5-a9fa-b1b6c1dc4836)


Conclusion
From the table, it can be concluded that Sample 3,6, and 9 shows the best accuracy of 0.97, and hence the most optimized parameters being kernel= linear, Nu= 4.53, epsilon= 7.02. From the convergence graph, it can be concluded that the objective function decreases and increases rapidly in the earlier iterations. In the later iterations, the function seems to be converging, and will ultimately lead to a stable solution after further more iterations.
